{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data with offset 0...\n",
      "✓ Saved data/locations_0.json\n",
      "Fetching data with offset 1000...\n",
      "✓ Saved data/locations_1.json\n",
      "Fetching data with offset 2000...\n",
      "✓ Saved data/locations_2.json\n",
      "Fetching data with offset 3000...\n",
      "✓ Saved data/locations_3.json\n",
      "Fetching data with offset 4000...\n",
      "✓ Saved data/locations_4.json\n",
      "Fetching data with offset 5000...\n",
      "✓ Saved data/locations_5.json\n",
      "Fetching data with offset 6000...\n",
      "✓ Saved data/locations_6.json\n",
      "Fetching data with offset 7000...\n",
      "✓ Saved data/locations_7.json\n",
      "Fetching data with offset 8000...\n",
      "✓ Saved data/locations_8.json\n",
      "Fetching data with offset 9000...\n",
      "✓ Saved data/locations_9.json\n",
      "Fetching data with offset 10000...\n",
      "✓ Saved data/locations_10.json\n",
      "Fetching data with offset 11000...\n",
      "✓ Saved data/locations_11.json\n",
      "Fetching data with offset 12000...\n",
      "✓ Saved data/locations_12.json\n",
      "Fetching data with offset 13000...\n",
      "✓ Saved data/locations_13.json\n",
      "Fetching data with offset 14000...\n",
      "✓ Saved data/locations_14.json\n",
      "Fetching data with offset 15000...\n",
      "✓ Saved data/locations_15.json\n",
      "Fetching data with offset 16000...\n",
      "✓ Saved data/locations_16.json\n",
      "Fetching data with offset 17000...\n",
      "✓ Saved data/locations_17.json\n",
      "Fetching data with offset 18000...\n",
      "✓ Saved data/locations_18.json\n",
      "Fetching data with offset 19000...\n",
      "✓ Saved data/locations_19.json\n",
      "Fetching data with offset 20000...\n",
      "✓ Saved data/locations_20.json\n",
      "Fetching data with offset 21000...\n",
      "✓ Saved data/locations_21.json\n",
      "Fetching data with offset 22000...\n",
      "✓ Saved data/locations_22.json\n",
      "Fetching data with offset 23000...\n",
      "✓ Saved data/locations_23.json\n",
      "Fetching data with offset 24000...\n",
      "✓ Saved data/locations_24.json\n",
      "Fetching data with offset 25000...\n",
      "✓ Saved data/locations_25.json\n",
      "Fetching data with offset 26000...\n",
      "✓ Saved data/locations_26.json\n",
      "Fetching data with offset 27000...\n",
      "✓ Saved data/locations_27.json\n",
      "Fetching data with offset 28000...\n",
      "✓ Saved data/locations_28.json\n",
      "Fetching data with offset 29000...\n",
      "✓ Saved data/locations_29.json\n",
      "Fetching data with offset 30000...\n",
      "✓ Saved data/locations_30.json\n",
      "Fetching data with offset 31000...\n",
      "✓ Saved data/locations_31.json\n",
      "Fetching data with offset 32000...\n",
      "✓ Saved data/locations_32.json\n",
      "Fetching data with offset 33000...\n",
      "✓ Saved data/locations_33.json\n",
      "Fetching data with offset 34000...\n",
      "✓ Saved data/locations_34.json\n",
      "Fetching data with offset 35000...\n",
      "✓ Saved data/locations_35.json\n",
      "Fetching data with offset 36000...\n",
      "✓ Saved data/locations_36.json\n",
      "Fetching data with offset 37000...\n",
      "✓ Saved data/locations_37.json\n",
      "Fetching data with offset 38000...\n",
      "✓ Saved data/locations_38.json\n",
      "Fetching data with offset 39000...\n",
      "No more data to fetch.\n",
      "Total records fetched: 38863\n",
      "Data saved in 39 files.\n"
     ]
    }
   ],
   "source": [
    "# import pandas module\n",
    "# import os module\n",
    "import pandas as pd\n",
    "import os\n",
    "# import json module\n",
    "import json\n",
    "# import time module\n",
    "import time\n",
    "# import urllib.request module\n",
    "import urllib.request\n",
    "# REPLACE WITH YOUR ACTUAL NOAA API TOKEN\n",
    "TOKEN = \"HHBZSMQFbcmOLuNpgrmyyCJTNOhQNpxH\"\n",
    "# NOAA API URL\n",
    "BASE_URL = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/locations\"\n",
    "# Headers for the API request\n",
    "HEADERS = {\n",
    "    'token': TOKEN\n",
    "\n",
    "}   \n",
    "# Function to make API request with retry on HTTPError 503\n",
    "def make_request(offset, retries=3, delay=5):\n",
    "    \"\"\"Make a request to the NOAA API with retry on HTTPError 503\"\"\"\n",
    "    url = f\"{BASE_URL}?limit=1000&offset={offset}\"\n",
    "    req = urllib.request.Request(url, headers=HEADERS)\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            with urllib.request.urlopen(req) as response:\n",
    "                return json.loads(response.read().decode('utf-8'))\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 503:\n",
    "                print(f\"HTTP 503 Service Unavailable. Retrying in {delay} seconds... (Attempt {attempt+1}/{retries})\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                raise\n",
    "    raise Exception(\"Failed to fetch data after multiple retries due to HTTP 503 error.\")\n",
    "# Function to save data to a file\n",
    "def save_to_file(data, file_index):\n",
    "    \"\"\"Save JSON data to a file\"\"\"\n",
    "    # Create data directory if it doesn't exist\n",
    "    data_dir = \"data\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    filename = os.path.join(data_dir, f\"locations_{file_index}.json\")\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"✓ Saved {filename}\")\n",
    "    return filename\n",
    "# Main function to fetch and save data\n",
    "def main():\n",
    "    \"\"\"Main function to fetch and save data from NOAA API\"\"\"\n",
    "    all_data = []\n",
    "    offset = 0\n",
    "    file_index = 0\n",
    "    total_records = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f\"Fetching data with offset {offset}...\")\n",
    "        data = make_request(offset)\n",
    "        \n",
    "        # Check if 'results' key exists and is not empty\n",
    "        if 'results' not in data or not data['results']:\n",
    "            print(\"No more data to fetch.\")\n",
    "            break\n",
    "        \n",
    "        all_data.extend(data['results'])\n",
    "        total_records += len(data['results'])\n",
    "        \n",
    "        # Save the current batch of data\n",
    "        save_to_file(data['results'], file_index)\n",
    "        \n",
    "        offset += 1000\n",
    "        file_index += 1\n",
    "        time.sleep(1)  # Be polite to the API\n",
    "        \n",
    "    print(f\"Total records fetched: {total_records}\")\n",
    "    print(f\"Data saved in {file_index} files.\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    '''\n",
    "This script fetches location data from the NOAA API using the provided API token.\n",
    "It retrieves the data in batches of 1000 records, handles HTTP 503 errors with retries,\n",
    "and saves each batch as a separate JSON file in the 'data' directory.\n",
    "The script continues fetching until no more data is available, and prints a summary at the end.\n",
    "You can adjust the API token, batch size, or error handling as needed for your use case.\n",
    "\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a file path (using os module) pointing to the pickled file from Exercise 1\n",
    "# Create a Pandas DataFrame from the pickled file. Use the file path as an argument.\n",
    "# Wait 5-10 minutes, then try again\n",
    "# python test_requests.py  \n",
    "# import pandas module\n",
    "# import os module\n",
    "import pandas as pd\n",
    "import os\n",
    "# import json module\n",
    "import json\n",
    "# import time module\n",
    "import time\n",
    "# import urllib.request module\n",
    "import urllib.request\n",
    "# REPLACE WITH YOUR ACTUAL NOAA API TOKEN\n",
    "TOKEN = \"HHBZSMQFbcmOLuNpgrmyyCJTNOhQNpxH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-03-06</td>\n",
       "      <td>2025-08-09</td>\n",
       "      <td>Grand Isle, VT 05458</td>\n",
       "      <td>0.95</td>\n",
       "      <td>ZIP:05458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1948-05-01</td>\n",
       "      <td>2025-08-09</td>\n",
       "      <td>Highgate Center, VT 05459</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:05459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-05-08</td>\n",
       "      <td>2025-08-09</td>\n",
       "      <td>Hinesburg, VT 05461</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:05461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955-11-01</td>\n",
       "      <td>2025-08-09</td>\n",
       "      <td>Huntington, VT 05462</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:05462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-03-06</td>\n",
       "      <td>2025-08-09</td>\n",
       "      <td>Isle la Motte, VT 05463</td>\n",
       "      <td>0.95</td>\n",
       "      <td>ZIP:05463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mindate     maxdate                       name  datacoverage         id\n",
       "0  1997-03-06  2025-08-09       Grand Isle, VT 05458          0.95  ZIP:05458\n",
       "1  1948-05-01  2025-08-09  Highgate Center, VT 05459          1.00  ZIP:05459\n",
       "2  1995-05-08  2025-08-09        Hinesburg, VT 05461          1.00  ZIP:05461\n",
       "3  1955-11-01  2025-08-09       Huntington, VT 05462          1.00  ZIP:05462\n",
       "4  1997-03-06  2025-08-09    Isle la Motte, VT 05463          0.95  ZIP:05463"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "# Load all JSON files from the 'data' directory into a single DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_dir = \"data\"\n",
    "all_data = []\n",
    "for filename in os.listdir(data_dir):\n",
    "\tif filename.startswith(\"locations_\") and filename.endswith(\".json\"):\n",
    "\t\twith open(os.path.join(data_dir, filename), \"r\") as f:\n",
    "\t\t\tall_data.extend(json.load(f))\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
